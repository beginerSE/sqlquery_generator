# import streamlit as st
# import pandas as pd

# st.title("BigQuery æ¤œå“ç”¨ã‚¯ã‚¨ãƒªç”Ÿæˆãƒ„ãƒ¼ãƒ«")

# # ç–‘ä¼¼ã‚¨ã‚¯ã‚»ãƒ«å…¥åŠ›ã‚¨ãƒªã‚¢ï¼ˆåˆæœŸå€¤2è¡Œï¼‰
# st.write("ğŸ“‹ ã‚«ãƒ©ãƒ åã¨ãƒ‡ãƒ¼ã‚¿å‹ã‚’æ‰‹å…¥åŠ›ã¾ãŸã¯ã‚³ãƒ”ãƒšã—ã¦ãã ã•ã„ï¼ˆå¿…è¦ã«å¿œã˜ã¦è¡Œã‚’è¿½åŠ ï¼‰")
# default_data = pd.DataFrame({
#     "col_name": ["", ""],
#     "data_type": ["STRING", "TIMESTAMP"]
# })
# edited_df = st.data_editor(default_data, num_rows="dynamic", use_container_width=True)



import streamlit as st
import pandas as pd
import io

st.title("BigQuery æ¤œå“ç”¨ã‚¯ã‚¨ãƒªç”Ÿæˆãƒ„ãƒ¼ãƒ«")

st.write("ğŸ“‹ Excelã§ä½œæˆã—ãŸã‚«ãƒ©ãƒ åã¨ãƒ‡ãƒ¼ã‚¿å‹ï¼ˆ2åˆ—ï¼‰ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ä¸‹ã«è²¼ã‚Šä»˜ã‘ã€ã€Œè¡¨ã«åæ˜ ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«è¡¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒ
if "column_data" not in st.session_state:
    st.session_state["column_data"] = pd.DataFrame({
        "col_name": ["", ""],
        "data_type": ["STRING", "TIMESTAMP"]
    })

# è²¼ã‚Šä»˜ã‘ç”¨ã‚¨ãƒªã‚¢
tsv_input = st.text_area("TSVå…¥åŠ›æ¬„ï¼ˆä¾‹: user_id\\tSTRINGï¼‰", height=150, key="tsv_input")

# TSVãƒ‘ãƒ¼ã‚¹é–¢æ•°
def parse_tsv(tsv_text):
    lines = tsv_text.strip().splitlines()
    data = []
    for line in lines:
        if '\t' in line:
            parts = line.split('\t')
            if len(parts) == 2:
                col_name, data_type = parts
                data.append({"col_name": col_name.strip(), "data_type": data_type.strip().upper()})
    return pd.DataFrame(data)

# è¡¨ã«åæ˜ ãƒœã‚¿ãƒ³
if st.button("ğŸ§¾ è¡¨ã«åæ˜ "):
    new_df = parse_tsv(tsv_input)
    if not new_df.empty:
        st.session_state["column_data"] = new_df
    else:
        st.warning("è²¼ã‚Šä»˜ã‘å†…å®¹ãŒç„¡åŠ¹ã§ã™ã€‚ã‚«ãƒ©ãƒ åã¨ãƒ‡ãƒ¼ã‚¿å‹ã‚’ã‚¿ãƒ–åŒºåˆ‡ã‚Šã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

# ç·¨é›†å¯èƒ½ãªè¡¨ã‚’è¡¨ç¤º
edited_df = st.data_editor(st.session_state["column_data"], num_rows="dynamic", use_container_width=True)

# ä»¥é™ã®ã‚¯ã‚¨ãƒªç”Ÿæˆå‡¦ç†ãªã©ã«ä½¿ã†ãŸã‚ä¿æŒ
st.session_state["column_data"] = edited_df




# ãƒ†ãƒ¼ãƒ–ãƒ«åã®å…¥åŠ›
table_ref_input = st.text_input("ğŸ”— BigQueryã®ãƒ†ãƒ¼ãƒ–ãƒ«åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹: project.dataset.tableï¼‰", "")

# æœŸé–“æŒ‡å®š
# use_date_filter = st.checkbox("ğŸ“… æœŸé–“æŒ‡å®šã‚’ä½¿ç”¨ã™ã‚‹")
# if use_date_filter:
#     term_column = st.text_input("ãƒ•ã‚£ãƒ«ã‚¿å¯¾è±¡ã®æ—¥ä»˜ã‚«ãƒ©ãƒ å", value="impression_date")
#     start_date = st.date_input("é–‹å§‹æ—¥", value=pd.to_datetime("2025-03-01"))
#     end_date = st.date_input("çµ‚äº†æ—¥", value=pd.to_datetime("2025-03-31"))
# else:
#     term_column = None


if use_date_filter:
    col_names = st.session_state["column_data"]["col_name"].dropna().unique().tolist()
    if col_names:
        term_column = st.selectbox("ãƒ•ã‚£ãƒ«ã‚¿å¯¾è±¡ã®æ—¥ä»˜ã‚«ãƒ©ãƒ å", options=col_names, index=0)
    else:
        st.warning("ã¾ãšã¯ã‚«ãƒ©ãƒ åã‚’è¡¨ã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        term_column = ""
    start_date = st.date_input("é–‹å§‹æ—¥", value=pd.to_datetime("2025-03-01"))
    end_date = st.date_input("çµ‚äº†æ—¥", value=pd.to_datetime("2025-03-31"))
else:
    term_column = None





# å®Ÿè¡Œãƒœã‚¿ãƒ³
if st.button("ğŸ› ï¸ ã‚¯ã‚¨ãƒªç”Ÿæˆ") and table_ref_input:
    selects = []

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¥ç”Ÿæˆ
    if use_date_filter:
        date_filter = f"WHERE DATE({term_column}) BETWEEN '{start_date}' AND '{end_date}'"
    else:
        date_filter = ""

    for _, row in edited_df.iterrows():
        col, dtype = row["col_name"], row["data_type"]
        if not col or not dtype:
            continue  # ç©ºè¡Œã¯ç„¡è¦–

        if dtype == "STRING":
            select = f"""
SELECT
'{col}' AS column_name,
NULL AS column_ronti,
'{dtype}_ARRAY' AS data_type,
NULL AS data_ronti,
NULL AS data_length,
NULL AS null_able,
NULL AS selection_columns,
NULL AS consideration_columns,
COUNT(*) AS total_count,
COUNTIF({col} IS NULL) AS null_count,
COUNTIF(TRIM({col}) = '') AS empty_string_count,
COUNT(DISTINCT {col}) AS unique_count,
SAFE_DIVIDE(COUNTIF({col} IS NULL OR TRIM({col}) = ''), COUNT(*)) * 100 AS missing_rate_percent,
SAFE_CAST(MIN({col}) AS STRING) AS min_value,
SAFE_CAST(MAX({col}) AS STRING) AS max_value
FROM `{table_ref_input}` {date_filter}
"""
        elif dtype in ["BOOLEAN", "INTEGER", "FLOAT", "TIMESTAMP", "DATE"]:
            select = f"""
SELECT
'{col}' AS column_name,
NULL AS column_ronti,
'{dtype}_ARRAY' AS data_type,
NULL AS data_ronti,
NULL AS data_length,
NULL AS null_able,
NULL AS selection_columns,
NULL AS consideration_columns,
COUNT(*) AS total_count,
COUNTIF({col} IS NULL) AS null_count,
NULL AS empty_string_count,
COUNT(DISTINCT {col}) AS unique_count,
SAFE_DIVIDE(COUNTIF({col} IS NULL), COUNT(*)) * 100 AS missing_rate_percent,
SAFE_CAST(MIN({col}) AS STRING) AS min_value,
SAFE_CAST(MAX({col}) AS STRING) AS max_value
FROM `{table_ref_input}` {date_filter}
"""
        else:
            continue

        selects.append(select.strip())

    full_query = "\nUNION ALL\n".join(selects)
    st.success("ğŸ‰ ã‚¯ã‚¨ãƒªãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚ä¸‹è¨˜ã‹ã‚‰ã‚³ãƒ”ãƒ¼ã—ã¦ãã ã•ã„ã€‚")
    st.code(full_query, language="sql")
    st.download_button("ğŸ“„ ã‚¯ã‚¨ãƒªã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã§ä¿å­˜", full_query, file_name="bq_inspection_query.sql")
